{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sadeelmu/deeplearning/blob/main/Transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4nQ3hrWPYR2"
      },
      "source": [
        "<style>\n",
        "r { color: Red }\n",
        "o { color: Orange }\n",
        "g { color: Green }\n",
        "b { color: Blue }\n",
        "l { color: lighblue }\n",
        "</style>\n",
        "\n",
        "\n",
        "<html>\n",
        "<body>\n",
        "<table style=\"border: 0; rules=none; font-size:28px\">\n",
        "<tr>\n",
        "<th rowspan=5><img width=\"200px\", height=\"70px\" src=\"https://raw.githubusercontent.com/camma-public/multibypass140/master/static/camma_logo_tr.png\"/></th>\n",
        "<td colspan=2 style=\"font-size:16px; color:blue; font-weight:bold\"><h1><b>Deep Learning for Computer Vision</b></h1></td>\n",
        "<th rowspan=5><img width=\"200px\", height=\"130px\" src=\"https://community.sap.com/legacyfs/online/storage/blog_attachments/2019/10/283545_NeuralNetwork_R_blue.png\"/></th>\n",
        "</tr>\n",
        "<tr><td>Instructor:</td><td>Dr. Chinedu Nwoye</td></tr>\n",
        "<tr><td colspan=2>(c) Research Group CAMMA</td></tr>\n",
        "<tr><td colspan=2>University of Strasbourg</td></tr>\n",
        "<tr><td>Website:</td><td><g>http://camma.u-strasbg.fr</g></td></tr>\n",
        "<tr><td colspan=4 style=\"text-align:centre; background-color:black; font-weight:bold\"><center><h3><o>Training by Transfer Learning </o></td></center></tr>\n",
        "</table>\n",
        "</body>\n",
        "</html>\n",
        "\n",
        "\n",
        "\n",
        "------------\n",
        "\n",
        "### Instructions\n",
        "\n",
        "- In this lab session we will experiment two scenarios of transfer learning in deep learning.\n",
        "  -  **Finetuning the convnet**: Instead of random initialization, we initialize the network with a pretrained network, like the one that is trained on imagenet 1000 dataset.\n",
        "  -  **ConvNet as fixed feature extractor**: Here, we will freeze the weights for all of the network except that of the final fully connected layer. This last fully connected layer is replaced with a new one with random weights and only this layer is trained.\n",
        "- Read all the descriptions and code.\n",
        "- Run the pre-completed cells.\n",
        "- Your will be required to complete all the TODO tasks in this exercise. Ask the instructor if you get in a hole.\n",
        "* You also have an additional `Bonus` exercise if you finish very quickly.\n",
        "\n",
        "### GPU activation\n",
        "\n",
        "- Be sure to have cuda enabled from your computer.\n",
        "- We can use Tensor Processing Unit (TPU) today.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run this cell in order to have pytorch TPU acceleration\n",
        "!pip install cloud-tpu-client==0.10 torch==1.12.0 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-1.12-cp37-cp37m-linux_x86_64.whl"
      ],
      "metadata": {
        "id": "-ox--zG2u8RN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports\n",
        "\n",
        "- Every experiments starts with importing the required libraries.\n",
        "- Check and see what libraries you don't know their usage."
      ],
      "metadata": {
        "id": "90HX0DQFT4CJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rU_1JC1qPYR3"
      },
      "outputs": [],
      "source": [
        "# License: BSD\n",
        "# Author: Sasank Chilamkurthy\n",
        "\n",
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "# from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import random\n",
        "import copy\n",
        "import urllib\n",
        "from zipfile import ZipFile\n",
        "\n",
        "%matplotlib inline\n",
        "plt.ion()   # interactive mode\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYmI5Lp7PYR4"
      },
      "source": [
        "Section 1: Dataset\n",
        "---------\n",
        "\n",
        "- We are going to finetune a model on a hymenoptera dataset to classify **ants** and **bees**.\n",
        "- This is a small subset of imagenet dataset.\n",
        "- The dataset statistics are as follows:\n",
        "  <html>\n",
        "    <table>\n",
        "      <tr>\n",
        "        <td>Split</td> <td># ants</td> <td># bees</td> <td># Total</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "        <td>Train</td> <td>100</td> <td>100</td> <td>200</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "        <td>Val</td> <td>25</td> <td>30</td> <td>55</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "        <td>Test</td> <td>50</td> <td>55</td> <td>105</td>\n",
        "      </tr>    \n",
        "      <tr>\n",
        "        <td>Total</td> <td>175</td> <td>185</td> <td>360</td>\n",
        "      </tr>\n",
        "    </table>\n",
        "  </html>\n",
        "\n",
        "- This is a very small dataset to generalize upon, if trained from scratch.\n",
        "- Since we are using transfer learning, we should be able to generalize reasonably well.\n",
        "\n",
        "\n",
        "**[1.1] Instructions**\n",
        "- Download and extract the dataset (https://seafile.unistra.fr/f/79ef71e90b5b4696b702/?dl=1) in your google drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download ants and bees dataset  (https://seafile.unistra.fr/f/79ef71e90b5b4696b702/?dl=1)\n",
        "\n",
        "!wget https://seafile.unistra.fr/f/79ef71e90b5b4696b702/?dl=1 --content-disposition &&  unzip -oq hymenoptera_data.zip -d hymenoptera_data"
      ],
      "metadata": {
        "id": "MytfJTY3UyTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**[1.2] Mount Drive**\n",
        "- If your drive is not visible, mount Google Drive, so we can see the data.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mQTaXJfbU4DG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Ne3uR1KRfZ-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[1.3] Data preparation**\n",
        "- Use torchvision and torch.utils.data packages for to build your data loader.\n",
        "- Here, we will treat the preprocessing of our training and validation data separately."
      ],
      "metadata": {
        "id": "QISIJd7rV1hc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyWQh-5WPYR5"
      },
      "outputs": [],
      "source": [
        "# Since we pretrained from imagenet, we need the statistics\n",
        "imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
        "imagenet_std = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "# Training data preprocessing: (Some data augmentation and normalization)\n",
        "train_transform = torchvision.transforms.Compose([\n",
        "        torchvision.transforms.RandomResizedCrop(224),\n",
        "        torchvision.transforms.RandomHorizontalFlip(),\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.Normalize(imagenet_mean, imagenet_std)\n",
        "    ])\n",
        "\n",
        "# Validation data preprocessing: just normalization\n",
        "eval_transform = torchvision.transforms.Compose([\n",
        "        torchvision.transforms.Resize(256),\n",
        "        torchvision.transforms.CenterCrop(224),\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.Normalize(imagenet_mean, imagenet_std)\n",
        "    ])\n",
        "\n",
        "# combine them\n",
        "data_transforms = {\n",
        "    'train': train_transform,\n",
        "    'val': eval_transform,\n",
        "    'test': eval_transform,\n",
        "}\n",
        "\n",
        "data_dir = 'hymenoptera_data'\n",
        "image_datasets = {x: torchvision.datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val', 'test']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=2) for x in ['train', 'val', 'test']}\n",
        "\n",
        "\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device is {}\".format(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX3TRo9_PYR6"
      },
      "source": [
        "**TODO [1.4]: Data visualization**\n",
        "- Visualize a few training images to understand the data augmentations.\n",
        "- We need a function to denormalize the images for display.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8su-Q75vPYR7"
      },
      "outputs": [],
      "source": [
        "def display_images(images, titles=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    images = images.data.permute(0,2,3,1).cpu().numpy()\n",
        "    images = imagenet_std.reshape([1,1,1,3]) * images + imagenet_mean.reshape([1,1,1,3])\n",
        "    images = np.clip(images, 0, 1)\n",
        "    num_imgs = len(images)\n",
        "    if titles == None: titles = [\"\"]*len(images)\n",
        "    plt.figure(figsize=(12,80))\n",
        "    for i in range(num_imgs):\n",
        "        plt.subplot(num_imgs//2, 2,i+1)    # the number of images in the grid is 5*5 (25)\n",
        "        plt.imshow(images[i])\n",
        "        plt.title(titles[i])\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "# Display images and labels\n",
        "display_images(inputs, titles=[class_names[x] for x in classes])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 2: Experiment Run Functions\n",
        "\n",
        "**TODO [2.1] Training function**\n",
        "- Let's write a function to train our model\n",
        "- It should include loss optimzation and performance evaluation."
      ],
      "metadata": {
        "id": "J0PF_WbhnHA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO find and add one line of code that is missing in the train_step function\n",
        "\n",
        "def train_step(inputs, labels, model, criterion, optimizer):\n",
        "    model.train() # set to training mode\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    optimizer.zero_grad() # zero the parameter gradients\n",
        "    _, preds = torch.max(outputs, 1) # get predicted labels\n",
        "    loss = criterion(outputs, labels) # compute loss\n",
        "    loss.backward() # backprops\n",
        "    optimizer.step() # optimization\n",
        "    # performance\n",
        "    batch_loss = loss.item() * inputs.size(0)\n",
        "    batch_accs = torch.sum(preds == labels.data)\n",
        "    return batch_loss, batch_accs"
      ],
      "metadata": {
        "id": "yBT2VClsnQ2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO [2.2] Evaluation function**\n",
        "- Let's write an evaluation function to evaluate our model.\n",
        "- It should do just inference and performance evaluation.\n"
      ],
      "metadata": {
        "id": "oQ7vk5XxnRUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: find and add one line of code that is missing in the function\n",
        "\n",
        "def eval_step(inputs, labels, model):\n",
        "    with torch.no_grad(): # stop gradient computation\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = model(inputs) # inference\n",
        "      preds = torch.argmax(outputs, axis=1)# get predicted labels\n",
        "      batch_accs = torch.sum(preds == labels.data) # performance\n",
        "    return batch_accs\n"
      ],
      "metadata": {
        "id": "SA16sJIcqnga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[2.3] Train and validate**\n",
        "- We can a loop of train and eval on each epoch\n",
        "- We include learning rate scheduling, and saving the best model after validation.\n",
        "- The parameter ``scheduler`` is an LR scheduler object from ``torch.optim.lr_scheduler``."
      ],
      "metadata": {
        "id": "MNarf5hxrfS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    start = time.time()\n",
        "\n",
        "    # Let's keep track of best performing weights\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # train loop\n",
        "        phase = 'train'\n",
        "        running_loss = 0.0\n",
        "        running_accs = 0\n",
        "        for inputs, labels in dataloaders[phase]: # Iterate over data.\n",
        "            loss, acc = train_step(inputs, labels, model, criterion, optimizer)\n",
        "            running_loss += loss\n",
        "            running_accs += acc\n",
        "        scheduler.step() # decay learning rate\n",
        "        train_epoch_loss = running_loss / dataset_sizes[phase]\n",
        "        train_epoch_acc = running_accs.double() / dataset_sizes[phase]\n",
        "\n",
        "        # validation loop\n",
        "        phase = 'val'\n",
        "        running_accs = 0\n",
        "        for inputs, labels in dataloaders[phase]: # Iterate over data.\n",
        "            acc = eval_step(inputs, labels, model)\n",
        "            running_accs += acc\n",
        "        val_epoch_acc = running_accs.double() / dataset_sizes[phase]\n",
        "\n",
        "        print('Epoch {}/{} >> TRAIN Loss: {:.4f} Acc: {:.4f}  | VAL Acc: {:4f}'.format(\n",
        "                epoch, num_epochs-1, train_epoch_loss, train_epoch_acc, val_epoch_acc))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # update weights if only it improves\n",
        "        if val_epoch_acc > best_acc:\n",
        "            best_acc = val_epoch_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    time_elapsed = time.time() - start\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('With best val accuracy: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "metadata": {
        "id": "m12sflwHrqwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wihs0HVqPYR8"
      },
      "source": [
        "**[2.4] Model prediction visualization**\n",
        "\n",
        "- Generic function to display predictions for a few images\n",
        "- We give a function to denormalize image for display."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EP-nO-2APYR9"
      },
      "outputs": [],
      "source": [
        "def visualize_preds(model, dataloader, choice):\n",
        "    iterloader = iter(dataloader)\n",
        "    if choice >= len(iterloader):\n",
        "        choice = 0\n",
        "    for _ in range(choice-1):\n",
        "        next(iterloader)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        inputs, labels = next(iterloader)\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(inputs) # inference\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "    titles = ['Label: {} | Predicted: {}'.format(class_names[gt], class_names[pd]) for gt, pd in zip(labels, preds)]\n",
        "    display_images(inputs, titles) # display\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcQgMfZuPYR9"
      },
      "source": [
        "Section 3: Finetuning the convnet\n",
        "----------------------\n",
        "\n",
        "**TODO [3.1] Model creation**\n",
        "- Load a pretrained model (resnet-18)\n",
        "- Create a new final fully connected layer to suit the dataset classes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rknYc5ChPYR-"
      },
      "outputs": [],
      "source": [
        "# ResNet-18 model pretrained on ImageNet.\n",
        "model_ft = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "# The number of classes of ImageNet = 1000, so the model last layer has 1000 dim and do not fit our data which has 2 classes\n",
        "num_input_filters = model_ft.fc.in_features\n",
        "num_out_filters = model_ft.fc.out_features\n",
        "print(\"Pretrained mode dim = ({}, {}) \".format(num_input_filters, num_out_filters) )\n",
        "\n",
        "# TODO: Create a linear layer with appropriate dim for your data\n",
        "custom_fc = ...\n",
        "\n",
        "# TODO: Replace the final layer of the pretrained model with your new final layer\n",
        "model_ft...\n",
        "\n",
        "# Set to device\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "\n",
        "# provide \"summary\" with model and input data size of (3, 244, 244)\n",
        "from torchsummary import summary\n",
        "summary(model_ft, (3, 224, 224))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO [3.2] Training properties**\n",
        "- Define the loss function.\n",
        "- Define the optimizer.\n",
        "- Define the learning rate decay schedule"
      ],
      "metadata": {
        "id": "osTNwogvNZd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# TODO: Create the optimizer (use learning rate of 0.001) to optimize all the parameters of the model. What does this mean?\n",
        "optimizer_ft = ...\n",
        "\n",
        "# Scheduler: Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "zeD_xpLeNqlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9RxVZo_PYR-"
      },
      "source": [
        "**TODO [3.3] Train and validate**\n",
        "\n",
        "- It should take around 15-25 min on CPU. On GPU though, it takes less than a minute.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_tWBbXDPYR_"
      },
      "outputs": [],
      "source": [
        "# TODO: train for 25 epochs\n",
        "\n",
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=...)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO [3.4] Test your model on the train and test sets**"
      ],
      "metadata": {
        "id": "Ygye01ZjOIsT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-kRl6SiPYR_"
      },
      "outputs": [],
      "source": [
        "# Testing on the train data\n",
        "# Find and add 2 missing lines in this code\n",
        "phase = 'train'\n",
        "for inputs, labels in dataloaders[phase]: # Iterate over data.\n",
        "    running_accs += acc\n",
        "train_epoch_acc = running_accs.double() / dataset_sizes[phase]\n",
        "print('TRAIN DATA Acc: {:.4f}'.format( train_epoch_acc))\n",
        "print('-' * 10)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Testing on the test data\n",
        "# Find and add 1 missing line in this code\n",
        "phase = 'test'\n",
        "running_accs = 0\n",
        "for inputs, labels in dataloaders: # Iterate over data.\n",
        "    acc = eval_step(inputs, labels, model_ft)\n",
        "    running_accs += acc\n",
        "train_epoch_acc = running_accs.double() / dataset_sizes[phase]\n",
        "print('TRAIN DATA Acc: {:.4f}'.format( train_epoch_acc))\n",
        "print('-' * 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO [3.5] Visualize some prediction of your model**"
      ],
      "metadata": {
        "id": "B9suutNwQaOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Visualize the images and prediction, manually find the images that your model failed on.\n",
        "\n",
        "iterloader = iter(dataloaders['test'])\n",
        "N = len(dataloaders['test'])\n",
        "choice = random.choice(list(range(N)))\n",
        "print(\"Chosing batch {} out of {} batches\".format(choice, N))\n",
        "\n",
        "visualize_preds(model_ft, dataloaders['test'], choice)"
      ],
      "metadata": {
        "id": "oWERncHPQhJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd9uS8G9PYSA"
      },
      "source": [
        "Section 4: ConvNet as fixed feature extractor\n",
        "----------------------------------\n",
        "\n",
        "- Here, we need to freeze all the network except the final layer. No re-training.\n",
        "\n",
        "- You can read more about this in the documentation\n",
        "`here <https://pytorch.org/docs/notes/autograd.html#excluding-subgraphs-from-backward>`__.\n",
        "\n",
        "**TODO [4.1] Creating the model**\n",
        "- We freeze the model by setting ``requires_grad == False`` to freeze the parameters so that the gradients are not computed in ``backward()``.\n",
        "- We create new final layer that is not frozen. So, only this layer will be trained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMLXUDmBPYSA"
      },
      "outputs": [],
      "source": [
        "# Again, we create a ResNet-18 model pretrained on ImageNet.\n",
        "model_conv = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "# TODO: Freeze all the model parameters\n",
        "for param in model_conv.parameters():\n",
        "    ...\n",
        "\n",
        "# The number of classes of ImageNet = 1000, so the model last layer has 1000 dim and do not fit our data which has 2 classes\n",
        "num_input_filters = model_conv.fc.in_features\n",
        "num_out_filters = model_conv.fc.out_features\n",
        "print(\"Pretrained mode dim = ({}, {}) \".format(num_input_filters, num_out_filters) )\n",
        "\n",
        "# TODO: Create a linear layer with appropriate dim for your data\n",
        "custom_fc = ...\n",
        "\n",
        "# Requires_grad=True by default, check it out\n",
        "print(\"Is the new layer trainable ? :\",  custom_fc.weight.requires_grad)\n",
        "\n",
        "# TODO: Replace the final layer of the pretrained model with your new final layer\n",
        "model_conv.fc = ...\n",
        "\n",
        "\n",
        "# Set to device\n",
        "model_conv = model_conv.to(device)\n",
        "\n",
        "\n",
        "# provide \"summary\" with model and input data size of (3, 244, 244)\n",
        "from torchsummary import summary\n",
        "summary(model_conv, (3, 224, 224))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO [4.2] Training properties**\n",
        "- Define the loss function.\n",
        "- Define the optimizer.\n",
        "- Define the learning rate decay schedule"
      ],
      "metadata": {
        "id": "3CEhRaAOR6iZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# TODO: Create optimizer to optimize only the parameters of final layer that you created as opposed to before.\n",
        "optimizer_conv = optim.SGD(..., lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "lZeFooxGR8JH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-2yCl7cPYSA"
      },
      "source": [
        "**[4.3] Train and validate**\n",
        "\n",
        "- On CPU this will take about half the time compared to previous scenario.\n",
        "- This is expected as gradients don't need to be computed for most of the network.\n",
        "- However, forward does need to be computed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Qvyy3fdPYSA"
      },
      "outputs": [],
      "source": [
        "# TODO: provide all the input arguments and train the model\n",
        "\n",
        "model_conv = train_model(...)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[4.4] Test on the train and test set**"
      ],
      "metadata": {
        "id": "TroERUlpSz-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing on the train data\n",
        "phase = 'train'\n",
        "running_accs = 0\n",
        "for inputs, labels in dataloaders[phase]: # Iterate over data.\n",
        "    acc = eval_step(inputs, labels, model_conv)\n",
        "    running_accs += acc\n",
        "train_epoch_acc = running_accs.double() / dataset_sizes[phase]\n",
        "print('TRAIN DATA Acc: {:.4f}'.format( train_epoch_acc))\n",
        "print('-' * 10)\n",
        "\n",
        "\n",
        "# Testing on the test data\n",
        "phase = 'test'\n",
        "running_accs = 0\n",
        "for inputs, labels in dataloaders[phase]: # Iterate over data.\n",
        "    acc = eval_step(inputs, labels, model_conv)\n",
        "    running_accs += acc\n",
        "train_epoch_acc = running_accs.double() / dataset_sizes[phase]\n",
        "print('TRAIN DATA Acc: {:.4f}'.format( train_epoch_acc))\n",
        "print('-' * 10)"
      ],
      "metadata": {
        "id": "IQjg9RiRS5L_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO [4.5] Visualize your predictions**"
      ],
      "metadata": {
        "id": "cU5AkM2AS7iR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBZ4MDXDPYSB"
      },
      "outputs": [],
      "source": [
        "# TODO: Visualize the images and prediction, manually find the images that your model failed on.\n",
        "\n",
        "iterloader = iter(dataloaders['test'])\n",
        "N = len(dataloaders['test'])\n",
        "choice = random.choice(list(range(N)))\n",
        "print(\"Chosing batch {} out of {} batches\".format(choice, N))\n",
        "\n",
        "visualize_preds(model_conv, dataloaders['test'], choice)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}