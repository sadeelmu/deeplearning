{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sadeelmu/deeplearning/blob/main/Rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMlUZTGtuAtq"
      },
      "source": [
        "# Lab 5a - RNN\n",
        "\n",
        "This lab session will introduce you to RNNs with a toy problem. We have simulated 3 types of insect motions in 2D: *ant* (steady), *slug* (fluctuating) and *grasshopper* (explosive). 2D positions over time are given as (num_times, 2) arrays; the first row contains the x coordinates, the second row the y coordinates. These will be fed to an RNN, which you will train to recognize the three motion types."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIFY2fD0RXXq"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as amt\n",
        "from matplotlib import rc\n",
        "import numpy as np\n",
        "from timeit import default_timer as timer\n",
        "import pickle\n",
        "import random\n",
        "\n",
        "rc('animation', html='jshtml')\n",
        "random.seed(2111994)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4jLgnP6vK0B"
      },
      "source": [
        "## Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjPeqdUSsqf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15f20f5d-5c33-4708-cecf-d2096628ef72"
      },
      "source": [
        "!wget --content-disposition https://seafile.unistra.fr/f/2fadadbc51b54de09c82/?dl=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-29 14:16:17--  https://seafile.unistra.fr/f/2fadadbc51b54de09c82/?dl=1\n",
            "Resolving seafile.unistra.fr (seafile.unistra.fr)... 77.72.44.41\n",
            "Connecting to seafile.unistra.fr (seafile.unistra.fr)|77.72.44.41|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://seafile.unistra.fr/seafhttp/files/bc7e16e4-55a8-46ea-a190-b698d8d776db/bugs.pickle [following]\n",
            "--2024-11-29 14:16:18--  https://seafile.unistra.fr/seafhttp/files/bc7e16e4-55a8-46ea-a190-b698d8d776db/bugs.pickle\n",
            "Reusing existing connection to seafile.unistra.fr:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21101550 (20M) [application/octet-stream]\n",
            "Saving to: ‘bugs.pickle’\n",
            "\n",
            "bugs.pickle         100%[===================>]  20.12M  52.6MB/s    in 0.4s    \n",
            "\n",
            "2024-11-29 14:16:18 (52.6 MB/s) - ‘bugs.pickle’ saved [21101550/21101550]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tp9Vw4kNvPUs"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odpX0ofNwAgl"
      },
      "source": [
        "Load it using the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryUA_lUxvVSH"
      },
      "source": [
        "DATA_PATH = \"bugs.pickle\"\n",
        "\n",
        "with open(DATA_PATH, \"rb\") as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "x_train = data[\"x_train\"]\n",
        "y_train = data[\"y_train\"]\n",
        "x_val   =  data[\"x_val\"]\n",
        "y_val   =  data[\"y_val\"]\n",
        "\n",
        "x_train = [np.transpose(v) for v in x_train]\n",
        "x_val = [np.transpose(v) for v in x_val]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-jdyk-6SoHg"
      },
      "source": [
        "This cell will load a few helpful functions for previewing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xvx4DtN0wjZp",
        "cellView": "both"
      },
      "source": [
        "BBOX_MARGIN = 1.2\n",
        "ANIM_REFRESH_TIME = 1000 / 60\n",
        "\n",
        "def trajectory_bbox(positions):\n",
        "  x_min = np.min(positions[0, :])\n",
        "  x_max = np.max(positions[0, :])\n",
        "  y_min = np.min(positions[1, :])\n",
        "  y_max = np.max(positions[1, :])\n",
        "  delta_x = x_max - x_min\n",
        "  delta_y = y_max - y_min\n",
        "  delta = BBOX_MARGIN * max(delta_x, delta_y) / 2\n",
        "  cx = (x_min + x_max) / 2\n",
        "  cy = (y_min + y_max) / 2\n",
        "  bbox_x1 = cx - delta\n",
        "  bbox_x2 = cx + delta\n",
        "  bbox_y1 = cy - delta\n",
        "  bbox_y2 = cy + delta\n",
        "  return bbox_x1, bbox_x2, bbox_y1, bbox_y2\n",
        "\n",
        "\n",
        "def plot_trajectory(positions, save_png=None):\n",
        "  bbox = trajectory_bbox(positions)\n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_subplot(111)\n",
        "  ax.plot(positions[0, :], positions[1, :])\n",
        "  ax.set_xlim(bbox[0], bbox[1])\n",
        "  ax.set_ylim(bbox[2], bbox[3])\n",
        "  ax.set_aspect(1.0)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def animate_motion(positions, n_frames, save_gif=None):\n",
        "  bbox = trajectory_bbox(positions)\n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_subplot(111)\n",
        "  handle = ax.scatter([], [], marker=\".\", color=\"r\", alpha=1)\n",
        "\n",
        "  def init():\n",
        "    ax.set_xlim(bbox[0], bbox[1])\n",
        "    ax.set_ylim(bbox[2], bbox[3])\n",
        "    ax.set_aspect(1.0)\n",
        "    return handle,\n",
        "\n",
        "  def update(id_t):\n",
        "    handle.set_offsets(positions[:, id_t])\n",
        "    return handle,\n",
        "\n",
        "  anim = amt.FuncAnimation(\n",
        "    fig,\n",
        "    update,\n",
        "    frames=np.arange(n_frames),\n",
        "    interval=ANIM_REFRESH_TIME,\n",
        "    init_func=init,\n",
        "    blit=True,\n",
        "    repeat=False\n",
        "  )\n",
        "  return anim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvpvKLXJwDrf"
      },
      "source": [
        "#### QUESTION 1\n",
        "\n",
        "Preview a sample here; change the value of ```ID_SAMPLE``` a few times to get familiar with the different motion types."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCHLdS6CSmVh"
      },
      "source": [
        "ID_SAMPLE = 0\n",
        "a = animate_motion(x_train[ID_SAMPLE], 200)\n",
        "plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-JtYctAMOR_"
      },
      "source": [
        "Animate:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvVapDtuUKH_"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zItbmLV9wjzb"
      },
      "source": [
        "We will package all of this into tensorflow datasets. **Batching makes the input a (48, num_times, 2) tensor**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvL6uM6Jws-E"
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "train_dataset = train_dataset.shuffle(10000).batch(48)\n",
        "val_dataset = val_dataset.batch(48)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXNvF1PvjNwh"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCfau-mhwtX0"
      },
      "source": [
        "## Model\n",
        "\n",
        "\n",
        "We will use an RNN with an LSTM cell. Here is the definition; pay attention to the syntax: first we create the *cell*, then ask Tensorflow for a function that will call it over the elements of a sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdnJ9HhAxMS_"
      },
      "source": [
        "class RNN_model(tf.keras.Model):\n",
        "  def __init__(self, memory_size):\n",
        "    super().__init__()\n",
        "    self._cell = tf.keras.layers.LSTMCell(memory_size)\n",
        "    self._rnn = tf.keras.layers.RNN(self._cell)\n",
        "    self._dense = tf.keras.layers.Dense(\n",
        "      units=N_CLASSES,\n",
        "      activation=\"softmax\"\n",
        "    )\n",
        "\n",
        "  def call(self, x):\n",
        "    res = x\n",
        "    res = self._rnn(x)\n",
        "    res = self._dense(res)\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Tvuq7yHxmJd"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG8euUk0xtip"
      },
      "source": [
        "Here is an optimizer for performing gradient descent, as well as the functions for one iteration of training and one iteration of evaluation.\n",
        "\n",
        "*You have seen them before; those are very generic. Being comfortable with them is highly valuable for your general understanding of deep learning*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTBrlLy7VKPM"
      },
      "source": [
        "optimizer = tf.keras.optimizers.RMSprop(0.005)\n",
        "\n",
        "@tf.function\n",
        "def train_step(inp, labels, model):\n",
        "  with tf.GradientTape() as tape:\n",
        "    outp = model(inp, training=True)\n",
        "    loss = tf.reduce_mean(tf.losses.sparse_categorical_crossentropy(labels, outp))\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  return loss\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def eval_step(inp, labels, model):\n",
        "  outp = model(inp, training=False)\n",
        "  pred = tf.cast(tf.argmax(outp, axis=1), tf.int32)\n",
        "  n_correct = tf.reduce_sum(\n",
        "    tf.cast(\n",
        "      tf.equal(pred, labels),\n",
        "      tf.float32\n",
        "    )\n",
        "  )\n",
        "  acc = n_correct / tf.cast(tf.shape(outp)[0], tf.float32)\n",
        "  return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVyZV8ZFMqDR"
      },
      "source": [
        "Here we create an RNN called ```rnn_0``` using the RNN_model class from before.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UULwNakB14u2"
      },
      "source": [
        "# Parameter save for convenience\n",
        "\n",
        "inp = np.zeros([1, 21, 2], dtype=np.float32)\n",
        "rnn_0 = RNN_model(32)\n",
        "s = rnn_0(inp)\n",
        "\n",
        "param_save = rnn_0.get_weights()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zYqNs8-yk9Y"
      },
      "source": [
        " #### QUESTION 2\n",
        "\n",
        "Train the RNN for 10000 iterations; report training loss and validation acccuracy every 100 iterations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLkD8hExNCBo"
      },
      "source": [
        "rnn_0.set_weights(param_save)\n",
        "\n",
        "average_training_losses = []\n",
        "training_losses = []\n",
        "average_val_accs = []\n",
        "val_accs = []\n",
        "\n",
        "for id_iter, (x_train_in, y_train_in) in zip(range(10000), train_dataset.repeat()):\n",
        "    # TODO: training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvlWNKAO15G2"
      },
      "source": [
        "#### QUESTION 3\n",
        "\n",
        "Run a prediction on a sample from the validation set, and preview the corresponding trajectory. Repeat as many times as you would like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OeY8jdD2iuW"
      },
      "source": [
        "# TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqRTIiANxMnp"
      },
      "source": [
        "#### QUESTION 4\n",
        "\n",
        "Modify BRNN_model to make it into a **bidirectional RNN**:\n",
        "- one RNN processing the sequence in chronological order\n",
        "- another processing it in reverse order\n",
        "- concatenate RNN outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zlcm4QMR42TH"
      },
      "source": [
        "class BRNN_model(tf.keras.Model):\n",
        "  def __init__(self, memory_size):\n",
        "    super().__init__()\n",
        "    # TODO\n",
        "    self._dense = tf.keras.layers.Dense(\n",
        "      units=N_CLASSES,\n",
        "      activation=\"softmax\"\n",
        "    )\n",
        "\n",
        "  def call(self, x):\n",
        "    res = x\n",
        "    # TODO\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zl_F6Cf0NgAy"
      },
      "source": [
        "Once the code for the bidirectional RNN class is ready, create the bidirectional RNN using the cell below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J436D_UHNsNY"
      },
      "source": [
        "# Parameter save for convenience\n",
        "\n",
        "inp = np.zeros([1, 21, 2], dtype=np.float32)\n",
        "brnn_0 = BRNN_model(32)\n",
        "s = brnn_0(inp)\n",
        "\n",
        "param_save = brnn_0.get_weights()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZYwT5_x42rf"
      },
      "source": [
        "#### QUESTION 5\n",
        "\n",
        "Train the bidirectional RNN for 10000 iterations; report training loss and validation acccuracy every 100 iterations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X739Zq-45iQ"
      },
      "source": [
        "# TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP_fKgeH457F"
      },
      "source": [
        "EXTRA QUESTION:\n",
        "\n",
        "The following function takes an array of 2D coordinates over time and draws the corresponding trajectory in a grayscale (86, 86) image.\n",
        "\n",
        "Convert the train and val dataset to trajectory images and try training a small CNN on the converted train set. How does the performance compare to the RNN?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNDkr6IvVyjV"
      },
      "source": [
        "def to_img(positions):\n",
        "    SZ = 86\n",
        "    bbox = trajectory_bbox(positions)\n",
        "    arr = np.zeros([SZ, SZ], dtype=np.float32)\n",
        "    for p in positions:\n",
        "        x = int((p[0] - bbox[0]) / (p[0] = bbox[1]) * SZ)\n",
        "        y = int((p[1] - bbox[2]) / (p[1] = bbox[3]) * SZ)\n",
        "        arr[y, x] = 1.0\n",
        "    return arr"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}